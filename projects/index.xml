<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Projects on Odin Hoff Gardå</title><link>https://odinhg.github.io/projects/</link><description>Recent content in Projects on Odin Hoff Gardå</description><generator>Hugo</generator><language>en-us</language><lastBuildDate>Fri, 05 Sep 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://odinhg.github.io/projects/index.xml" rel="self" type="application/rss+xml"/><item><title>RAG-based Personal Chatbot</title><link>https://odinhg.github.io/projects/odibot/</link><pubDate>Fri, 05 Sep 2025 00:00:00 +0000</pubDate><guid>https://odinhg.github.io/projects/odibot/</guid><description>&lt;p>Now you can &lt;a href="https://odinhg-odibot-chat.hf.space/">chat with me (link)&lt;/a> without me being online! This was a hobby project to create a personal chatbot using Retrieval-Augmented Generation (RAG) techniques. A collection of Markdown files about me are chunked and embedded into a vector database using &lt;a href="https://github.com/SecludedCoder/chonkie">Chonkie&lt;/a> and &lt;a href="https://www.trychroma.com/">Chroma&lt;/a>, respectively. Combining this with the &lt;code>Llama-3.1 8B Instruct&lt;/code> language model using the &lt;a href="https://huggingface.co/">Hugging Face&lt;/a> inference API, I built a chatbot that can answer questions about me based on the documents provided. If you are interested in building something similar, feel free to contact me.&lt;/p></description></item><item><title>Chatbot from Scratch</title><link>https://odinhg.github.io/projects/decoder_transformer/</link><pubDate>Fri, 29 Aug 2025 00:00:00 +0000</pubDate><guid>https://odinhg.github.io/projects/decoder_transformer/</guid><description>&lt;p>For the course &amp;ldquo;Deep Learning (INF265)&amp;rdquo; at the University of Bergen (UiB) in the spring of 2025, I created a project where the goal was to implement a transformer model from scratch and train it on a dataset of question-answer pairs. The model is a decoder-only transformer that uses causal self-attention to generate answers to short questions. This is similar to the GPT-2 architecture, but much smaller and simpler.&lt;/p>
&lt;p>I think this is a good exercise to understand the inner workings of transformer models and how they can be used for text generation tasks. And for fun, I also created a simple chatbot interface using Streamlit to interact with the trained model.&lt;/p></description></item><item><title>Traffic Volume Forecasting with Graph Neural Networks</title><link>https://odinhg.github.io/projects/traffic_gnn/</link><pubDate>Fri, 29 Aug 2025 00:00:00 +0000</pubDate><guid>https://odinhg.github.io/projects/traffic_gnn/</guid><description>&lt;p>Can we use geometric priors to improve traffic volume forecasting? In this project, we use Graph Neural Networks (GNNs) to predict traffic volume in western Norway (Bergen area) using historical traffic data. Using both a manually crafted graph encoding road connectivity and a nearest neighbor graph based on sensor locations. I did this project as part of the course INF367A on geometric deep learning at the University of Bergen during my PhD.&lt;/p></description></item><item><title>Solving NRK's Former with Monte Carlo Tree Search</title><link>https://odinhg.github.io/projects/nrk_former/</link><pubDate>Thu, 28 Aug 2025 00:00:00 +0000</pubDate><guid>https://odinhg.github.io/projects/nrk_former/</guid><description>&lt;p>In this project, I implemented the &lt;a href="https://dke.maastrichtuniversity.nl/m.winands/documents/CGSameGame.pdf">Single-Player Monte Carlo Tree Search (SP-MCTS)&lt;/a> (Schadd et al., 2008) algorithm to solve &lt;a href="https://www.nrk.no/former-1.17105310">NRK Former&lt;/a>, a puzzle game developed by the Norwegian Broadcasting Corporation (NRK). The goal of the game is to remove all blocks from a 9x7 grid using as few moves as possible by clicking on connected blocks of the same color.&lt;/p>
&lt;p>Check out the repository and try it out yourself!&lt;/p>
&lt;p>&lt;em>&lt;strong>Note:&lt;/strong> I also implemented a model using Deep Q-Networks (DQN) to solve the same game, but I found that the MCTS approach was more effective for this particular problem. You can find that implementation &lt;a href="https://github.com/odinhg/nrk-former-dql">here&lt;/a>.&lt;/em>&lt;/p></description></item><item><title>3D Point Cloud Classification with Geometric Deep Learning</title><link>https://odinhg.github.io/projects/modelnet_pointcloud_classification/</link><pubDate>Mon, 28 Jul 2025 00:00:00 +0000</pubDate><guid>https://odinhg.github.io/projects/modelnet_pointcloud_classification/</guid><description>&lt;p>This repository contains code for conducting experiments on 3D point cloud classification using various geometric deep learning architectures. The experiments are performed on the ModelNet40 dataset, which consists of 3D models from 40 different categories. The starting point for this repository was the DeepSets architecture for permutation invariant learning on sets (for example point clouds). We wanted to test wether using graph neural networks (GNNs) and more complex architectures could improve performance on this task by incorporating
additional geometric priors.&lt;/p></description></item><item><title>Group Equivariant Convolutional Neural Networks</title><link>https://odinhg.github.io/projects/group_equivariant_cnns/</link><pubDate>Sun, 29 Jun 2025 00:00:00 +0000</pubDate><guid>https://odinhg.github.io/projects/group_equivariant_cnns/</guid><description>&lt;p>The goal of this project was to implement and compare group equivariant convolutional neural networks (GCNNs) against standard convolutional neural networks (CNNs) and a smoothed version of CNNs (averaging over all group symmetries) on a binary stereo image classification task (sunny or rainy weather). The group considered in this project is the dihedral group of order 8 which acts on stereo images by rotations and reflections.&lt;/p>
&lt;p>GCNNs are a type of neural network that are designed to be equivariant to certain transformations of the input data and were introduced by &lt;a href="https://arxiv.org/abs/1602.07576">Taco Cohen and Max Welling in 2016&lt;/a>. I did this project as part of the course INF367A on geometric deep learning at the University of Bergen during my PhD.&lt;/p></description></item><item><title>Dentology: Topology for Dentists</title><link>https://odinhg.github.io/projects/dentology/</link><pubDate>Thu, 29 May 2025 00:00:00 +0000</pubDate><guid>https://odinhg.github.io/projects/dentology/</guid><description>&lt;p>Using topological data analysis (TDA) to detect cavities in 3D models of teeth. This is done by computing the persistent homology of the sublevel sets of a height function on the tooth surface. The idea is that cavities will correspond to topological features (specifically, 1-dimensional holes) that persist over a wide range of height values. This was an April Fools project I made for fun, but the implementation does work (of course).&lt;/p></description></item><item><title>Codenames Spymaster Bot</title><link>https://odinhg.github.io/projects/codenames_spymaster/</link><pubDate>Mon, 10 Feb 2025 00:00:00 +0000</pubDate><guid>https://odinhg.github.io/projects/codenames_spymaster/</guid><description>&lt;p>In this project, I developed a spymaster bot for the popular board game Codenames using pre-trained word embeddings and a scoring function inspired by contrastive learning methods. The bot generates clues by analyzing the relationships between words in the game, aiming to connect multiple words from the same team while avoiding words associated with the opposing team, neutral words, and the assassin word.&lt;/p></description></item><item><title>SimCLR from Scratch</title><link>https://odinhg.github.io/projects/simclr/</link><pubDate>Wed, 29 Jan 2025 00:00:00 +0000</pubDate><guid>https://odinhg.github.io/projects/simclr/</guid><description>&lt;p>In this project, I implemented SimCLR for self-supervised learning of embeddings of plankton image data. The main components were the random augmentation module, the projection head, and the NT-Xent based loss function. I observed that SimCLR performed best on this small dataset compared to other models, likely due to its ability to learn general features without overfitting. It would be interesting to see how it performs on a larger dataset with more classes.&lt;/p></description></item><item><title>Python Crash Course for INF264</title><link>https://odinhg.github.io/projects/python_crash_course/</link><pubDate>Tue, 10 Sep 2024 00:00:00 +0000</pubDate><guid>https://odinhg.github.io/projects/python_crash_course/</guid><description>&lt;p>A Python crash course on NumPy and Matplotlib I made for students taking the course INF264 – Introduction to Machine Learning at the University of Bergen. It consists of Jupyter notebooks covering the basics of NumPy and Matplotlib with exercises to practice. It also comes with solutions to the exercises and a guide on how to set up a Python environment using Anaconda.&lt;/p></description></item><item><title>ArcFace and Triplet Network</title><link>https://odinhg.github.io/projects/arcface_triplets/</link><pubDate>Sat, 29 Jun 2024 00:00:00 +0000</pubDate><guid>https://odinhg.github.io/projects/arcface_triplets/</guid><description>&lt;p>In this project, I implemented a Triplet Network with various online mining strategies to improve training, and the Angular Margin Loss from ArcFace. The goal was to create latent representations of plankton images and compare performance on the downstream task of training a simple classifier on embeddings. Both models achieved good separation on average for all classes in the training data, but struggled with the last class in the unseen data. The ArcFace embeddings showed more connected clusters in the unseen data compared to the Triplet Loss embeddings.&lt;/p></description></item><item><title>Q-Learning Tutorial in Norwegian</title><link>https://odinhg.github.io/projects/qlearning_tutorial/</link><pubDate>Mon, 25 Mar 2024 00:00:00 +0000</pubDate><guid>https://odinhg.github.io/projects/qlearning_tutorial/</guid><description>&lt;p>This is a tutorial I made for students taking INF100 (Introduction to Programming) in spring 2024. Our goal is to create a program where an agent learns to solve a maze using Q-learning, a form of reinforcement learning. The repository contains a step-by-step guide to implementing the Q-learning algorithm in Python, along with the slides I used for the accompanying lecture. Note that the tutorial is written in Norwegian.&lt;/p></description></item><item><title>Ordl - Wordle clone for your terminal</title><link>https://odinhg.github.io/projects/ordl/</link><pubDate>Thu, 10 Aug 2023 00:00:00 +0000</pubDate><guid>https://odinhg.github.io/projects/ordl/</guid><description>&lt;p>A simple terminal-based Wordle clone written in Python, designed for quick gameplay while waiting for machine learning models to train. The game uses a dictionary of five-letter Norwegian words, but the word list can swapped out for other languages or custom lists.&lt;/p></description></item><item><title>SLEDE8 Disassembler</title><link>https://odinhg.github.io/projects/slede8_disassembler/</link><pubDate>Sat, 10 Jun 2023 00:00:00 +0000</pubDate><guid>https://odinhg.github.io/projects/slede8_disassembler/</guid><description>&lt;p>A simple disassembler for the esoteric programming language SLEDE8, invented by PST (Norwegian Police Security Service) for one of their Christmas CTFs. Probably not useful for anything now that the CTF is over, but I made it for fun and as a learning exercise in Python.&lt;/p></description></item></channel></rss>